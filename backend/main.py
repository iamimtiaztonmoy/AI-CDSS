"""FastAPI application for the comprehensive CDSS backend."""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Any, Dict

from .models import RecommendationRequest, RecommendationResponse
from .rag import load_rag, GuidelineRAG

app = FastAPI(title="Comprehensive CDSS Backend", version="1.0.0")

rag_engine: GuidelineRAG | None = None


class ChatRequest(BaseModel):
    """Schema for free‑form chat queries."""

    query: str


class ChatResponse(BaseModel):
    """Response model for the chat endpoint."""

    answer: str


@app.on_event("startup")
async def startup_event() -> None:
    """Initialize the retrieval engine when the application starts."""
    global rag_engine
    rag_engine = load_rag()


@app.post("/recommendation", response_model=RecommendationResponse)
async def get_recommendation(request: RecommendationRequest) -> RecommendationResponse:
    """
    Generate a recommendation for the given patient based on their symptoms.

    The symptoms list is concatenated into a query string for the retrieval
    engine.  A snippet of the most relevant guideline paragraph is returned
    along with a simple explanation.
    """
    global rag_engine
    if rag_engine is None:
        raise HTTPException(status_code=500, detail="RAG engine is not initialized")
    query = ", ".join(request.symptoms)
    snippet, score = rag_engine.query(query)
    explanation = (
        "This recommendation is generated by retrieving the most relevant "
        "section from the clinical guidelines based on the patient's reported "
        "symptoms.  The engine uses a TF‑IDF vectorizer to match keywords."
    )
    return RecommendationResponse(
        patient_id=request.patient_id,
        query=query,
        snippet=snippet,
        explanation=explanation,
    )


@app.post("/chat", response_model=ChatResponse)
async def chat_endpoint(chat: ChatRequest) -> ChatResponse:
    """
    Answer a free‑form question about the guideline documents.

    The query string is passed directly to the retrieval engine and the most
    relevant paragraph is returned.  A more advanced implementation could
    generate answers using a language model conditioned on the retrieved text.
    """
    global rag_engine
    if rag_engine is None:
        raise HTTPException(status_code=500, detail="RAG engine is not initialized")
    query = chat.query.strip()
    if not query:
        raise HTTPException(status_code=400, detail="Query cannot be empty")
    snippet, score = rag_engine.query(query)
    return ChatResponse(answer=snippet)
